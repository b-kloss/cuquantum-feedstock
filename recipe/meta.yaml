# Make sure the component versions are consistent with the SDK version!
{% set version = "23.10.0.6" %}
{% set cusv_version = "1.5.0" %}
{% set cutn_version = "2.3.0" %}

{% if cuda_compiler_version in (None, "None", True, False) %}
{% set cuda_major = 0 %}
{% else %}
{% set cuda_major = environ.get("cuda_compiler_version", "11.8").split(".")[0]|int %}
{% endif %}

# prioritize nompi variant via build number
{% set build_num = 2 %}
{% if mpi == 'nompi' %}
{% set cutn_build = build_num + 100 %}
{% else %}
{% set cutn_build = build_num %}
{% endif %}

# encode mpi dependency in the build string
{% if mpi != "nompi" %}
{% set mpi_prefix = "mpi_" + mpi %}
{% else %}
{% set mpi_prefix = "nompi" %}
{% endif %}

package:
  name: cuquantum-sdk  # dummy
  version: {{ version }}

source:
  - url: https://developer.download.nvidia.com/compute/cuquantum/redist/cuquantum/linux-x86_64/cuquantum-linux-x86_64-{{ version }}_cuda{{ cuda_major }}-archive.tar.xz  # [linux64]
    sha256: 7e214d6020190ff7299a483448a4d44f54c98b69fd8dc9866a187d995ecc46e2  # [linux64 and (cuda_compiler_version or "").startswith("11")]
    sha256: 5ff77bd5cf62fab02e598fe5e1b1617d521207552808173e135f9a9607f56bad  # [linux64 and (cuda_compiler_version or "").startswith("12")]

  - url: https://developer.download.nvidia.com/compute/cuquantum/redist/cuquantum/linux-sbsa/cuquantum-linux-sbsa-{{ version }}_cuda{{ cuda_major }}-archive.tar.xz  # [aarch64]
    sha256: a8f403a17663d4c7304b6d7944ba2c78afc630dad7741577dde3bc849b54fc79  # [aarch64 and (cuda_compiler_version or "").startswith("11")]
    sha256: 395ac98d0993fc3419395dce86947cbdfe0abf556bb4dc674dcffcf939e0d482  # [aarch64 and (cuda_compiler_version or "").startswith("12")]

  - url: https://developer.download.nvidia.com/compute/cuquantum/redist/cuquantum/linux-ppc64le/cuquantum-linux-ppc64le-{{ version }}_cuda{{ cuda_major }}-archive.tar.xz  # [ppc64le]
    sha256: 983c3fdf50c0ad1639a98eae0eca670b60e02516d5240e37aac4726abcbce839  # [ppc64le and (cuda_compiler_version or "").startswith("11")]
    sha256: ddef9c8c7ac977ca8477af07a53cc3d497f39c1feed88a0cb6a5d73ba9f3a1db  # [ppc64le and (cuda_compiler_version or "").startswith("12")]

  - url: https://github.com/NVIDIA/cuQuantum/archive/refs/tags/v{{ ".".join(version.split(".")[:3]) }}.tar.gz
    sha256: 0c819a21d0dfc158d19c44f999d2caeb19a9f4567baa0e77d712a83315c039e8

build:
  number: {{ build_num }}
  skip: true  # [not linux or cuda_compiler_version not in ("11.8", "12.0")]

outputs:

  - name: cuquantum
    version: {{ version }}
    build:
      number: {{ build_num }}
    requirements:
      build:
      host:
      run:
        - {{ pin_subpackage('custatevec', max_pin='x.x.x') }}
        - {{ pin_subpackage('cutensornet', max_pin='x.x.x') }}
    test:
      commands:
        - echo "ok!"

  - name: custatevec
    version: {{ cusv_version }}
    build:
      number: {{ build_num }}
      script:
        - mkdir -p $PREFIX/include                                            # [linux]
        - mv include/custatevec.h $PREFIX/include/                            # [linux]
        - mkdir -p $PREFIX/lib                                                # [linux]
        - mv lib/libcustatevec.so* $PREFIX/lib/                               # [linux]
      run_exports:
        - {{ pin_subpackage('custatevec', max_pin='x') }}
      ignore_run_exports_from:
        - {{ compiler('cuda') }}
      missing_dso_whitelist:
        - '*/libcublas.so*'    # [(cuda_compiler_version or "").startswith("11")]
        - '*/libcublasLt.so*'  # [(cuda_compiler_version or "").startswith("11")]
      post-link: post-link  # this is supported by conda-build, but undocumented
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}
        - sysroot_{{ target_platform }} 2.17  # [linux]
      host:
        - libcublas  # [(cuda_compiler_version or "").startswith("12")]
        - cuda-version {{ cuda_major }}.0
      run:
        - cudatoolkit                                     # [(cuda_compiler_version or "").startswith("11")]
        - {{ pin_compatible('libcublas', max_pin='x') }}  # [(cuda_compiler_version or "").startswith("12")]
        - {{ pin_compatible('cuda-version', max_pin='x') }}
      # this should be set once conda-forge supports newer glibc
      # https://github.com/conda-forge/conda-forge.github.io/issues/1941
      # run_constrained:
      #   - __glibc >=2.27  # [aarch64 or ppc64le]
    # apparently conda-build supports full test section spec, the document is super outdated
    test:
      requires:
        - git
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}
        # make sure we pick up the version matching the docker,
        # or the linker would complain
        - cuda-version {{ cuda_compiler_version }}.*
        - sysroot_{{ target_platform }} 2.17  # [linux]
      files:
        - test_load_elf.c
        - cusv_run_test.sh
      commands:
        - ./cusv_run_test.sh {{ version }}
    about:
      home: https://developer.nvidia.com/cuquantum-sdk
      license: LicenseRef-cuQuantum-Software-License-Agreement
      license_url: https://docs.nvidia.com/cuda/cuquantum/latest/license.html
      license_file: LICENSE
      summary: 'cuStateVec: A High-Performance Library for State Vector Quantum Simulators'
      description: |
        NVIDIA cuStateVec is a high-performance GPU library dedicated to operations with state vectors
        for expressing quantum algorithms. cuStateVec is a component of the NVIDIA cuQuantum SDK.

        The packages cuquantum, custatevec, and cutensornet are governed by the NVIDIA cuQuantum
        Software License Agreement (EULA). By downloading and using the packages,
        you accept the terms and conditions of the NVIDIA cuQuantum EULA -
        https://docs.nvidia.com/cuda/cuquantum/license.html
      doc_url: https://docs.nvidia.com/cuda/cuquantum/latest/custatevec/
      dev_url: https://github.com/NVIDIA/cuQuantum

  - name: cutensornet
    version: {{ cutn_version }}
    build:
      number: {{ cutn_build }}
      string: "{{ mpi_prefix }}_h{{ PKG_HASH }}_{{ cutn_build }}"
      script:
        - mkdir -p $PREFIX/include                                            # [linux]
        - mv include/cutensornet* $PREFIX/include/                            # [linux]
        - mkdir -p $PREFIX/lib                                                # [linux]
        - mv lib/libcutensornet.so* $PREFIX/lib/                              # [linux]

        # build the wrapper lib
        - $GCC -shared -std=c11 -fPIC -I$CUDA_PATH/include -I$PREFIX/include distributed_interfaces/cutensornet_distributed_interface_mpi.c -L$PREFIX/lib -lmpi -o $PREFIX/lib/libcutensornet_distributed_interface_mpi.so  # [mpi != 'nompi' and (cuda_compiler_version or "").startswith("11")]
        - $GCC -shared -std=c11 -fPIC $CFLAGS -I$PREFIX/include distributed_interfaces/cutensornet_distributed_interface_mpi.c -L$PREFIX/lib -lmpi -o $PREFIX/lib/libcutensornet_distributed_interface_mpi.so               # [mpi != 'nompi' and (cuda_compiler_version or "").startswith("12")]
        # copy activate/deactivate scripts
        - mkdir -p "${PREFIX}/etc/conda/activate.d"  # [mpi != 'nompi']
        - cp "${RECIPE_DIR}/cutn-activate.sh" "${PREFIX}/etc/conda/activate.d/cutn-activate.sh"  # [mpi != 'nompi']
        - mkdir -p "${PREFIX}/etc/conda/deactivate.d"  # [mpi != 'nompi']
        - cp "${RECIPE_DIR}/cutn-deactivate.sh" "${PREFIX}/etc/conda/deactivate.d/cutn-deactivate.sh"  # [mpi != 'nompi']
      run_exports:
        - {{ pin_subpackage('cutensornet', max_pin='x') }} {{ mpi_prefix }}_*
      ignore_run_exports_from:
        - {{ compiler('cuda') }}
      missing_dso_whitelist:
        - '*/libcutensor.so*'  # [(cuda_compiler_version or "").startswith("11")]
        - '*/libcublas.so*'    # [(cuda_compiler_version or "").startswith("11")]
        - '*/libcublasLt.so*'  # [(cuda_compiler_version or "").startswith("11")]
        - '*/libcusolver.so*'  # [(cuda_compiler_version or "").startswith("11")]
      post-link: post-link  # this is supported by conda-build, but undocumented
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}
        - sysroot_{{ target_platform }} 2.17  # [linux]
      host:
        - {{ mpi }}  # [mpi != 'nompi']
        - cutensor
        - libcublas        # [(cuda_compiler_version or "").startswith("12")]
        - libcusolver      # [(cuda_compiler_version or "").startswith("12")]
        - cuda-version {{ cuda_major }}.0
      run:
        - {{ pin_compatible('cutensor', max_pin='x') }}
        - {{ pin_compatible('libcublas', max_pin='x') }}    # [(cuda_compiler_version or "").startswith("12")]
        - {{ pin_compatible('libcusolver', max_pin='x') }}  # [(cuda_compiler_version or "").startswith("12")]
        - {{ pin_compatible('cuda-version', max_pin='x') }}
        # conda-forge mpich does not support CUDA...
        - {{ mpi }} * external*  # [mpi == 'mpich']
        - {{ mpi }}              # [mpi == 'openmpi']
      run_constrained:
        # if users also wanna install mpi, we need to ensure the nompi version is not
        # picked by the solver, we do so by createing a conflict
        - openmpi <0.a0          # [mpi == 'nompi']
        - mpich <0.a0            # [mpi == 'nompi']
    # apparently conda-build supports full test section spec, the document is super outdated
    test:
      requires:
        - git
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}
        # make sure we pick up the version matching the docker,
        # or the linker would complain
        - cuda-version {{ cuda_compiler_version }}.*
        - sysroot_{{ target_platform }} 2.17  # [linux]
      files:
        - test_load_elf.c
        - cutn_run_test.sh
      commands:
        - ./cutn_run_test.sh {{ version }}
        - echo $CUTENSORNET_COMM_LIB
        - test -n $CUTENSORNET_COMM_LIB  # [mpi != 'nompi']
        - test -f $CUTENSORNET_COMM_LIB  # [mpi != 'nompi']
        - test -z $CUTENSORNET_COMM_LIB  # [mpi == 'nompi']
    about:
      home: https://developer.nvidia.com/cuquantum-sdk
      license: LicenseRef-cuQuantum-Software-License-Agreement
      license_url: https://docs.nvidia.com/cuda/cuquantum/license.html
      license_file: LICENSE
      summary: 'cuTensorNet: A High-Performance Library for Tensor Network Computations'
      description: |
        NVIDIA cuTensorNet is a high-performance GPU library for tensor network computations,
        a component of the NVIDIA cuQuantum SDK.

        The packages cuquantum, custatevec, and cutensornet are governed by the NVIDIA cuQuantum
        Software License Agreement (EULA). By downloading and using the packages,
        you accept the terms and conditions of the NVIDIA cuQuantum EULA -
        https://docs.nvidia.com/cuda/cuquantum/license.html
      doc_url: https://docs.nvidia.com/cuda/cuquantum/latest/cutensornet/
      dev_url: https://github.com/NVIDIA/cuQuantum

  - name: cuquantum-python
    version: {{ ".".join(version.split(".")[:3]) }}
    version: 23.06.0
    build:
      number: {{ build_num }}
      # build cuQuantum Python in a CUDA agnostic way to serve both CUDA 11/12
      # (note: this would still use cuda_compiler_version to calculate hash)
      skip: true  # [not (cuda_compiler_version or "").startswith("11") or (py < 39)]
      script_env:
        - CUQUANTUM_ROOT=$PREFIX
        - CUTENSOR_ROOT=$PREFIX
      script:
        # The CUDA 11 docker image sets CUDA_PATH for us
        - export CUDA_PATH=$BUILD_PREFIX/targets/x86_64-linux/   # [linux64 and (cuda_compiler_version or "").startswith("12")]
        - export CUDA_PATH=$BUILD_PREFIX/targets/sbsa-linux/     # [aarch64 and (cuda_compiler_version or "").startswith("12")]
        - export CUDA_PATH=$BUILD_PREFIX/targets/ppc64le-linux/  # [ppc64le and (cuda_compiler_version or "").startswith("12")]
        - cd python
        # {{ PYTHON }} is not resolved properly in multi-output recipes...
        - $PREFIX/bin/python -m pip install --no-deps --no-build-isolation -vv .
      ignore_run_exports_from:
        # let cuquantum handle the CUDA deps
        - {{ compiler('cuda') }}
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}
        - sysroot_{{ target_platform }} 2.17  # [linux]
        - cross-python_{{ target_platform }}  # [build_platform != target_platform]
        - python                              # [build_platform != target_platform]
        - cython                              # [build_platform != target_platform]
      host:
        - python
        - pip
        - cython
        - custatevec ={{ cusv_version }}
        - cutensornet ={{ cutn_version }}
        - packaging
      run:
        - python
        - numpy >=1.21,<2
        - cupy >=10.0
        - {{ pin_subpackage('custatevec', max_pin='x') }}
        - {{ pin_subpackage('cutensornet', max_pin='x') }}
        - cuda-version >=11.0.*,<13.a0  # again, cuQuantum Python is "CUDA agnostic"
      run_constrained:
        - pytorch >=1.10
        - mpi4py >=3.1.0
        # we don't have to pin Qiskit or Cirq here because their versions are fairly recent on conda-forge
    test:
      requires:
        - cuda-driver-dev  # [linux and (cuda_compiler_version or "").startswith("12")]
      commands:
        # perform the import test via CLI because we need to load the stub for CUDA 12
        - export CUDA_STUB="$PREFIX/lib/stubs/libcuda.so"  # [(cuda_compiler_version or "").startswith("12")]
        - LD_PRELOAD="$CUDA_STUB" python -c "import cuquantum"
        - LD_PRELOAD="$CUDA_STUB" python -c "import cuquantum.custatevec"
        - LD_PRELOAD="$CUDA_STUB" python -c "import cuquantum.cutensornet"
        - LD_PRELOAD="$CUDA_STUB" python -m cuquantum --includes --libs --target custatevec --target cutensornet
    about:
      home: https://developer.nvidia.com/cuquantum-sdk
      license: BSD-3-Clause
      license_url: https://docs.nvidia.com/cuda/cuquantum/license.html#nvidia-cuquantum-python
      license_file: LICENSE
      summary: "cuQuantum Python: Python APIs for NVIDIA cuQuantum SDK"
      description: |
        NVIDIA cuQuantum Python provides Python bindings and high-level object-oriented
        models for accessing the full functionalities of NVIDIA cuQuantum SDK from Python.
      doc_url: https://docs.nvidia.com/cuda/cuquantum/latest/python/
      dev_url: https://github.com/NVIDIA/cuQuantum

about:
  home: https://developer.nvidia.com/cuquantum-sdk
  license: LicenseRef-cuQuantum-Software-License-Agreement
  license_url: https://docs.nvidia.com/cuda/cuquantum/license.html
  license_file: LICENSE
  summary: 'cuQuantum SDK: A High-Performance Library for Accelerating Quantum Information Science'
  description: |
    NVIDIA cuQuantum is an SDK of optimized libraries and tools for accelerating quantum computing workflows.
    Using NVIDIA GPU Tensor Core GPUs, developers can use cuQuantum to speed up quantum circuit simulations
    based on state vector and tensor network methods by orders of magnitude. Two major components of the
    SDK are

      - cuStateVec: a high-performance library for state vector computations
      - cuTensorNet: a high-performance library for tensor network computations

    The packages cuquantum, custatevec, and cutensornet are governed by the NVIDIA cuQuantum
    Software License Agreement (EULA). By downloading and using the packages,
    you accept the terms and conditions of the NVIDIA cuQuantum EULA -
    https://docs.nvidia.com/cuda/cuquantum/license.html
  doc_url: https://docs.nvidia.com/cuda/cuquantum/latest/index.html
  dev_url: https://github.com/NVIDIA/cuQuantum

extra:
  recipe-maintainers:
    - leofang
    - JeremyWangNVDA
    - mtjrider
    - yangcal
    - DmitryLyakh
