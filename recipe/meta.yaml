{% set version = "22.05.0.41" %}

package:
  name: cuquantum
  version: {{ version }}

source:
  url: https://developer.download.nvidia.com/compute/cuquantum/redist/cuquantum/linux-x86_64/cuquantum-linux-x86_64-{{ version }}-archive.tar.xz    # [linux64]
  url: https://developer.download.nvidia.com/compute/cuquantum/redist/cuquantum/linux-sbsa/cuquantum-linux-sbsa-{{ version }}-archive.tar.xz        # [aarch64]
  url: https://developer.download.nvidia.com/compute/cuquantum/redist/cuquantum/linux-ppc64le/cuquantum-linux-ppc64le-{{ version }}-archive.tar.xz  # [ppc64le]

  sha256: 3804ee39c96610ca1f1a644adde568344530f9377444b5309e20bc7d7e12ce57  # [linux64]
  sha256: 4aefee0523ada81939a5376061532293dd34ac55e5efe7a3ab76bf7c87800aed  # [aarch64]
  sha256: 641cbace1da172eb7bfca8c063a5b1194056c8a1d8d80b0bfa84bfcaa60d3a68  # [ppc64le]

build:
  number: 0
  skip: True  # [win or ppc64le or cuda_compiler_version != "11.2"]
  script:
    - mkdir -p $PREFIX/include                                            # [linux]
    - cp -r include/* $PREFIX/include/                                    # [linux]
    - mkdir -p $PREFIX/lib                                                # [linux]
    - mv lib/*.so* $PREFIX/lib/                                           # [linux]

    # Patch for conda-forge:
    # According to the CUDA support matrix, we require glibc 2.27+ on aarch64-sbsa
    # and ppc64le, while conda-forge is still on 2.17. However, given that powf is
    # the only offending symbol that needs a newer glibc, it is the easiest if we
    # just patch it.
    - patchelf --clear-symbol-version powf $PREFIX/lib/libcustatevec.so   # [aarch64 or ppc64le]
    #- patchelf --clear-symbol-version __tls_get_addr_opt $PREFIX/lib/libcustatevec.so  # [ppc64le]
#    # Fix undefined references, see
#    # https://github.com/conda-forge/cuquantum-feedstock/pull/5#issuecomment-1024625275
#    - patchelf --add-needed libcublas.so.11 $PREFIX/lib/libcustatevec.so  # [ppc64le]
  run_exports:
    - {{ pin_subpackage('cuquantum', max_pin='x.x') }}
  ignore_run_exports_from:
    - {{ compiler('cuda') }}
  missing_dso_whitelist:
    - '*/libcutensor.so*'
    - '*/libcublas.so*'
    - '*/libcublasLt.so*'

requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cuda') }}
    - sysroot_linux-64 2.17  # [linux64]
  host:
  run:
    - _openmp_mutex  # [linux]
    - libgomp        # [linux]
    - cudatoolkit >=11.0,<12
    - cutensor >=1.5,<2

test:
  requires:
    - git
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}
    - sysroot_linux-64 2.17  # [linux64]
    # make sure we pick up the version matching the docker,
    # or the linker would complain 
    - cudatoolkit {{ cuda_compiler_version }}
  files:
    - test_load_elf.c        # [linux]

about:
  home: https://developer.nvidia.com/cuquantum-sdk
  license: LicenseRef-cuQuantum-Software-License-Agreement
  license_url: https://docs.nvidia.com/cuda/cuquantum/license.html
  license_file: docs/cuQuantum_license.pdf
  summary: "cuQuantum SDK: A High-Performance Library for Accelerating Quantum Information Science"
  description: |
    NVIDIA cuQuantum is an SDK of optimized libraries and tools for accelerating quantum computing workflows.
    Using NVIDIA GPU Tensor Core GPUs, developers can use cuQuantum to speed up quantum circuit simulations
    based on state vector and tensor network methods by orders of magnitude. Two major components of the
    SDK are

      - cuStateVec: a high-performance library for state vector computations
      - cuTensorNet: a high-performance library for tensor network computations

    License Agreements:- The packages are governed by the NVIDIA cuQuantum
    Software License Agreement (EULA). By downloading and using the packages,
    you accept the terms and conditions of the NVIDIA cuQuantum EULA -
    https://docs.nvidia.com/cuda/cuquantum/license.html
  doc_url: https://docs.nvidia.com/cuda/cuquantum/index.html
  dev_url: https://developer.nvidia.com/cuquantum-downloads

extra:
  recipe-maintainers:
    - leofang
    - JeremyWangNVDA
    - mtjrider
